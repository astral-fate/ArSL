{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f74347c-86d5-466c-88f9-b93d7c38fee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Loaded class mapping.\n",
      "Model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Class mapping (Load it if you saved it)\n",
    "try:\n",
    "    # class_mapping = torch.load('class_mapping.pth')\n",
    "    class_mapping = torch.load('class_mapping.pth', weights_only=True)\n",
    "    idx_to_class = class_mapping  # Use the original mapping directly\n",
    "    num_classes = len(class_mapping)\n",
    "    print(\"Loaded class mapping.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: class_mapping.pth not found.  Make sure the file exists and the path is correct.\")\n",
    "    exit() # Terminate the program as it cannot proceed without the class mapping\n",
    "\n",
    "\n",
    "# Model Definition (MUST MATCH the training model EXACTLY)\n",
    "class ArSLNet(nn.Module):\n",
    "    def __init__(self, num_classes=32):  # Ensure num_classes matches your training data\n",
    "        super(ArSLNet, self).__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256 * 14 * 14, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "# Load the trained model\n",
    "model = ArSLNet(num_classes=num_classes).to(device)  # Important: Instantiate the model *before* loading the state dict.  Pass num_classes!\n",
    "try:\n",
    "    # model.load_state_dict(torch.load('best_arsl_model.pth', map_location=device))  # Load to correct device.\n",
    "    model.load_state_dict(torch.load('best_arsl_model.pth', map_location=device, weights_only=True))\n",
    "    model.eval()  # Set to evaluation mode\n",
    "    print(\"Model loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: best_arsl_model.pth not found.  Ensure the file exists and the path is correct.\")\n",
    "    exit()  # Exit if the model isn't found\n",
    "except RuntimeError as e:\n",
    "    print(f\"RuntimeError while loading the model: {e}\")\n",
    "    print(\"Check that the model architecture in this script EXACTLY matches the architecture used during training.\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "# Image Preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def predict_image(image_path):\n",
    "    \"\"\"Predicts the class of an image given its path.\"\"\"\n",
    "    try:\n",
    "        img = Image.open(image_path).convert('RGB')  # Ensure image is RGB\n",
    "    except FileNotFoundError:\n",
    "        return \"Error: Image not found.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error loading image: {e}\"\n",
    "\n",
    "    img_tensor = transform(img).unsqueeze(0).to(device)  # Add batch dimension and move to device\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(img_tensor)\n",
    "        probabilities = torch.nn.functional.softmax(output[0], dim=0)  # Softmax to get probabilities\n",
    "        _, predicted_idx = torch.max(output, 1)\n",
    "        predicted_class = idx_to_class[predicted_idx.item()]\n",
    "        confidence = probabilities[predicted_idx.item()].item() * 100\n",
    "\n",
    "    return predicted_class, confidence\n",
    "\n",
    "\n",
    "# OpenCV Integration (Real-time prediction from webcam)\n",
    "def opencv_realtime():\n",
    "    \"\"\"Opens the webcam and predicts Arabic Sign Language in real time.\"\"\"\n",
    "    cap = cv2.VideoCapture(0)  # Use 0 for default webcam\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open webcam.\")\n",
    "        return\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error: Could not read frame.\")\n",
    "            break\n",
    "\n",
    "        # Convert the OpenCV frame to PIL Image for processing\n",
    "        try:\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) #Correct color issue with opencv\n",
    "            pil_img = Image.fromarray(frame_rgb)\n",
    "            img_tensor = transform(pil_img).unsqueeze(0).to(device) # Add batch dimension\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output = model(img_tensor)\n",
    "                probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "                _, predicted_idx = torch.max(output, 1)\n",
    "                predicted_class = idx_to_class[predicted_idx.item()] #Get predicted class\n",
    "                confidence = probabilities[predicted_idx.item()].item() * 100\n",
    "\n",
    "\n",
    "            label = f\"Prediction: {predicted_class} (Confidence: {confidence:.2f}%)\"\n",
    "            cv2.putText(frame, label, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing frame: {type(e).__name__} - {e}\")  # Print the exception type and message\n",
    "            cv2.putText(frame, f\"Error: {type(e).__name__}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2) # just print error name\n",
    "\n",
    "        cv2.imshow('Arabic Sign Language Prediction', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):  # Press 'q' to quit\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# Run real-time prediction from webcam\n",
    "opencv_realtime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72ef018f-a956-4a6a-861c-7f272176b808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class mapping: {0: 'ain', 1: 'al', 2: 'aleff', 3: 'bb', 4: 'dal', 5: 'dha', 6: 'dhad', 7: 'fa', 8: 'gaaf', 9: 'ghain', 10: 'ha', 11: 'haa', 12: 'jeem', 13: 'kaaf', 14: 'khaa', 15: 'la', 16: 'laam', 17: 'meem', 18: 'nun', 19: 'ra', 20: 'saad', 21: 'seen', 22: 'sheen', 23: 'ta', 24: 'taa', 25: 'thaa', 26: 'thal', 27: 'toot', 28: 'waw', 29: 'ya', 30: 'yaa', 31: 'zay'}\n",
      "Idx to class mapping: {'ain': 0, 'al': 1, 'aleff': 2, 'bb': 3, 'dal': 4, 'dha': 5, 'dhad': 6, 'fa': 7, 'gaaf': 8, 'ghain': 9, 'ha': 10, 'haa': 11, 'jeem': 12, 'kaaf': 13, 'khaa': 14, 'la': 15, 'laam': 16, 'meem': 17, 'nun': 18, 'ra': 19, 'saad': 20, 'seen': 21, 'sheen': 22, 'ta': 23, 'taa': 24, 'thaa': 25, 'thal': 26, 'toot': 27, 'waw': 28, 'ya': 29, 'yaa': 30, 'zay': 31}\n"
     ]
    }
   ],
   "source": [
    "print(\"Class mapping:\", class_mapping)\n",
    "print(\"Idx to class mapping:\", idx_to_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2568a0c3-7e1c-4c6e-8cde-fa4eb8767311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: laam, Confidence: 42.32%\n"
     ]
    }
   ],
   "source": [
    "# Example Usage (Single image prediction)\n",
    "image_path = 'ba.png'  # Replace with the path to your image\n",
    "prediction, confidence = predict_image(image_path)\n",
    "print(f\"Predicted class: {prediction}, Confidence: {confidence:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4eba81-0fbd-4c74-afd9-ac0770a739d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (torch_gpu)",
   "language": "python",
   "name": "torch_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
